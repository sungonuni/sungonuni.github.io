---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a second-year Ph.D student of [Efficient Computing Lab](https://sites.google.com/view/eh-p) in the Department of Computer Science & Engineering at [POSTECH](https://www.postech.ac.kr), advised by Prof. Eunhyeok Park. Before joining POSTECH, I completed my B.S. in Department of Computer Science & Engineering in [Kyung Hee University](https://www.khu.ac.kr).

I'm interested in model compression, particularly in enhancing memory efficiency and acceleration of AI through **Quantization**. My recent research focuses on **Low-Precision Training** and fine-tuning, which aims to achieve acceleration, memory reduction, and performance maximization during training. Iâ€™m currently focusing on **Training-Inference Acceleration via Quantization and Low-rank Approximation**.

_**KEYWORD**: 
 Low-Precision Training, Quantization for LLM, Low-rank Approximation, CUDA Kernel optimization_


News
-----
- [Mar. 02, 2025] 1 paper has been accepted to [**ICML 2025**](https://icml.cc//).
- [Feb. 25, 2025] 1 paper has been accepted to [**CVPR 2025**](https://cvpr.thecvf.com/).
- [Oct. 28, 2024] 1 paper has been accepted to [**WACV 2025**](https://wacv2025.thecvf.com/).


Publications
-----

- [HOT: Hadamard-based Optimized Training](https://arxiv.org/abs/2503.21261)  
**Seonggon Kim**, Juncheol Shin, Seung-taek Woo, Eunhyeok Park  
Computer Vision and Pattern Recognition (**CVPR 2025**), Nashville.

- HoLA: Overcoming the full-finetuning with Hadamard-oriented LoRA  
**Seonggon Kim**, Taehyeon Kim, Byeori Kim, Eunhyeok Park  
Neural Information Processing Systems (**NeurIPS 2025**, Under review), San Diego.

- [Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation](https://arxiv.org/abs/2505.23651)  
Juncheol Shin, Minsang Seok, **Seonggon Kim**, Eunhyeok Park  
International Conference on Machine Learning (**ICML 2025**), Vancouver.

- [PTQ4VM: Post-training Quantization for Visual Mamba](https://arxiv.org/abs/2412.20386)  
Younghyun Cho\*, Changhun Lee\*, **Seonggon Kim**, Eunhyeok Park  
Winter Conference on Applications of Computer Vision (**WACV 2025 <span style="color:red">Oral</span>**), Tucson.

- [HLQ: Fast and Efficient Backpropagation via Hadamard Low-rank Quantization](https://arxiv.org/abs/2406.15102)  
**Seonggon Kim**, Eunhyeok Park  
arXiv 2406.


Experience
-----
- **Software Engineer Intern**, Jul. 2022 - Feb. 2023   
Spirent Communications, San Jose, CA, USA

- **Software Engineer Intern**, Feb. 2022 - Jun. 2022  
Common Computer, Seoul, Korea

- **Research Intern**, Mar. 2021 - Dec. 2021  
SI Analytics, Daejeon, Korea


Awards & Honors
-----
- ETHDenver 2022 Blockchain Hackathon NFT project, **3rd Prize**  
SporkDAO, Feb. 2022

- CVPR 2021 Earthvision workshop, Land Cover Classification Challenge, **5th Prize**  
CVPR, Jun. 2021


Education
-----
- **M.S/Ph.D.** in Computer Science and Engineering, [POSTECH](https://www.postech.ac.kr)  
Sep. 2023 - Present

- **B.S.** in Computer Science and Engineering, [Kyung Hee University](https://www.khu.ac.kr)  
Feb. 2017 - Aug. 2023

Teaching Experience
-----
- Teaching Assistant, Mar. 2025 - June. 2025  
CSED311: Computer Architecture, [POSTECH](https://www.postech.ac.kr) 
